"""AIä¼šè©±ç”¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã€‚"""

import asyncio
import json
import uuid
from datetime import datetime

import streamlit as st

from src.config.settings import settings
from src.core.models.agent_model import ChatMessage, MessageRole
from src.core.services.agent_service import AgentService
from src.ui.components.chat_interface import (
    render_chat_history,
    render_chat_input,
    render_error_message,
)
from src.utils.logger import get_logger

logger = get_logger(__name__)


def _should_reset_session(selected_model: str) -> bool:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã™ã¹ãã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚

    Args:
        selected_model: é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ID

    Returns:
        ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã™ã¹ããªã‚‰True
    """
    return "current_model" not in st.session_state or st.session_state.current_model != selected_model


def _reset_session(selected_model: str) -> None:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚

    Args:
        selected_model: é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ID
    """
    st.session_state.agent_service = AgentService(model_id=selected_model)
    st.session_state.current_model = selected_model
    st.session_state.current_session_id = str(uuid.uuid4())
    st.session_state.chat_messages = []
    logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {selected_model} ã«å¤‰æ›´ã—ã€æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹: {st.session_state.current_session_id}")


def initialize_session_state(selected_model: str) -> None:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹å¤‰æ•°ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚

    Args:
        selected_model: é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ID
    """
    # ãƒ¢ãƒ‡ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
    if _should_reset_session(selected_model):
        _reset_session(selected_model)

    # å¿…è¦ãªçŠ¶æ…‹å¤‰æ•°ã‚’åˆæœŸåŒ–
    if "current_session_id" not in st.session_state:
        st.session_state.current_session_id = str(uuid.uuid4())
        logger.info(f"æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ: {st.session_state.current_session_id}")

    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []

    if "is_processing" not in st.session_state:
        st.session_state.is_processing = False


def start_new_session() -> None:
    """æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ã€‚"""
    st.session_state.current_session_id = str(uuid.uuid4())
    st.session_state.chat_messages = []
    logger.info(f"æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {st.session_state.current_session_id}")
    st.success(f"æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {st.session_state.current_session_id[:8]}...")


def _display_user_message(user_input: str) -> ChatMessage:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«è¿½åŠ ã™ã‚‹ã€‚

    Args:
        user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        ä½œæˆã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    from src.core.models.agent_model import TextPart

    user_message = ChatMessage(
        role=MessageRole.USER,
        timestamp=datetime.now(),
        parts=[TextPart(content=user_input)],
    )
    st.session_state.chat_messages.append(user_message)

    with st.chat_message("user"):
        st.markdown(user_input)

    return user_message


async def _stream_assistant_response(user_input: str) -> list:
    """ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚

    Args:
        user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Returns:
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒ¼ãƒ„ã®ãƒªã‚¹ãƒˆ
    """
    from src.core.models.agent_model import MessagePart, TextPart, ToolExecution, ToolPart
    from src.ui.components.chat_interface import render_tool_execution

    parts: list[MessagePart] = []
    current_text = ""

    # ç¾åœ¨è¡¨ç¤ºä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆç”¨ã‚³ãƒ³ãƒ†ãƒŠ
    text_container = st.container()
    text_placeholder = text_container.empty()

    async for chunk, tool_execution in st.session_state.agent_service.stream_message(
        session_id=st.session_state.current_session_id,
        message=user_input,
    ):
        if chunk:
            current_text += chunk
            text_placeholder.markdown(current_text + "â–Œ")

        if tool_execution:
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºå®š
            if current_text:
                text_placeholder.markdown(current_text)
                parts.append(TextPart(content=current_text))
                current_text = ""

            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’è¿½åŠ 
            tool_exec = ToolExecution(
                tool_name=tool_execution["tool_name"],
                input_data=tool_execution["input_data"],
                output_data=tool_execution["output_data"],
            )
            parts.append(ToolPart(tool_execution=tool_exec))

            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’è¡¨ç¤º
            tool_container = st.container()
            with tool_container:
                render_tool_execution(tool_exec)

            # æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆç”¨ã«æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒŠã¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
            text_container = st.container()
            text_placeholder = text_container.empty()

    # æœ€å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ãƒ¼ãƒˆã‚’ç¢ºå®š
    if current_text:
        text_placeholder.markdown(current_text)
        parts.append(TextPart(content=current_text))

    return parts


async def send_message(user_input: str) -> None:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¦å¿œç­”ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    from src.core.models.agent_model import TextPart

    _display_user_message(user_input)

    with st.chat_message("assistant"):
        try:
            st.session_state.is_processing = True

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹å‰ã«å¾…æ©Ÿã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚’è¡¨ç¤º
            with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè€ƒãˆä¸­..."):
                parts = await _stream_assistant_response(user_input)

            assistant_message = ChatMessage(
                role=MessageRole.ASSISTANT,
                timestamp=datetime.now(),
                parts=parts,
            )
            st.session_state.chat_messages.append(assistant_message)

        except Exception as e:
            logger.error(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            st.markdown(error_msg)
            st.session_state.chat_messages.append(
                ChatMessage(
                    role=MessageRole.ASSISTANT,
                    timestamp=datetime.now(),
                    parts=[TextPart(content=error_msg)],
                )
            )

        finally:
            st.session_state.is_processing = False


def handle_chat_controls(controls: dict) -> None:
    """ãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã€‚"""
    if controls["new_session"]:
        start_new_session()
        st.rerun()

    if controls["export_chat"]:
        export_conversation()


def export_conversation() -> None:
    """ç¾åœ¨ã®ä¼šè©±ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã€‚"""
    if st.session_state.chat_messages:
        export_data = {
            "session_id": st.session_state.current_session_id,
            "exported_at": datetime.now().isoformat(),
            "messages": [msg.model_dump(mode="json") for msg in st.session_state.chat_messages],
        }
        st.download_button(
            label="ğŸ“¥ JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json.dumps(export_data, ensure_ascii=False, indent=2),
            file_name=f"chat_export_{st.session_state.current_session_id}.json",
            mime="application/json",
        )
    else:
        st.info("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“")


def render_agent_chat_page(controls: dict) -> None:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã™ã‚‹ã€‚"""
    logger.debug("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ä¸­")

    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    selected_model = controls.get("selected_model", "claude-sonnet-4-20250514")

    # APIã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
    from src.infrastructure.llm.llm_factory import MODEL_CONFIGS

    model_config = MODEL_CONFIGS.get(selected_model)
    if not model_config:
        render_error_message(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {selected_model}")
        st.stop()

    provider: str = model_config["provider"]  # type: ignore
    if provider == "anthropic" and not settings.anthropic_api_key:
        render_error_message(
            "Anthropic APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«ANTHROPIC_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
        st.stop()
    elif provider == "openai" and not settings.openai_api_key:
        render_error_message("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    initialize_session_state(selected_model)

    handle_chat_controls(controls)

    if st.session_state.chat_messages:
        render_chat_history(st.session_state.chat_messages)

    if user_input := render_chat_input():
        if not st.session_state.is_processing:
            asyncio.run(send_message(user_input))
            st.rerun()
        else:
            st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
